{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEw0bp_xotvH",
        "outputId": "4cd8a498-0ebe-43cf-a037-09ec0c5f843a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest ---\n",
            "Train Accuracy: 0.995\n",
            "Test Accuracy:  0.837\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.82      0.77      0.79       128\n",
            "          D2       0.68      0.83      0.75       128\n",
            "        HCCD       0.95      0.90      0.92       128\n",
            "        LCCD       0.87      0.70      0.77       129\n",
            "        MCCD       0.82      0.95      0.88       129\n",
            "           N       0.94      0.99      0.97       128\n",
            "          PD       1.00      0.94      0.97       129\n",
            "          T1       0.92      0.91      0.92       128\n",
            "          T2       0.64      0.78      0.70       128\n",
            "          T3       0.82      0.60      0.69       128\n",
            "\n",
            "    accuracy                           0.84      1283\n",
            "   macro avg       0.85      0.84      0.84      1283\n",
            "weighted avg       0.85      0.84      0.84      1283\n",
            "\n",
            "\n",
            "--- Extra Trees ---\n",
            "Train Accuracy: 0.953\n",
            "Test Accuracy:  0.807\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.85      0.69      0.76       128\n",
            "          D2       0.71      0.75      0.73       128\n",
            "        HCCD       0.90      0.92      0.91       128\n",
            "        LCCD       0.79      0.67      0.72       129\n",
            "        MCCD       0.79      0.89      0.84       129\n",
            "           N       0.74      0.99      0.85       128\n",
            "          PD       0.98      0.91      0.95       129\n",
            "          T1       0.84      0.95      0.89       128\n",
            "          T2       0.73      0.67      0.70       128\n",
            "          T3       0.75      0.62      0.68       128\n",
            "\n",
            "    accuracy                           0.81      1283\n",
            "   macro avg       0.81      0.81      0.80      1283\n",
            "weighted avg       0.81      0.81      0.80      1283\n",
            "\n",
            "\n",
            "--- Decision Tree ---\n",
            "Train Accuracy: 0.881\n",
            "Test Accuracy:  0.733\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.66      0.77      0.71       128\n",
            "          D2       0.66      0.52      0.58       128\n",
            "        HCCD       0.85      0.88      0.87       128\n",
            "        LCCD       0.70      0.61      0.65       129\n",
            "        MCCD       0.76      0.83      0.79       129\n",
            "           N       0.85      0.99      0.91       128\n",
            "          PD       1.00      0.91      0.96       129\n",
            "          T1       0.92      0.64      0.76       128\n",
            "          T2       0.47      0.51      0.49       128\n",
            "          T3       0.56      0.66      0.61       128\n",
            "\n",
            "    accuracy                           0.73      1283\n",
            "   macro avg       0.74      0.73      0.73      1283\n",
            "weighted avg       0.74      0.73      0.73      1283\n",
            "\n",
            "\n",
            "--- Logistic Regression ---\n",
            "Train Accuracy: 0.478\n",
            "Test Accuracy:  0.508\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.60      0.30      0.40       128\n",
            "          D2       0.66      0.27      0.39       128\n",
            "        HCCD       0.71      0.97      0.82       128\n",
            "        LCCD       0.28      0.50      0.36       129\n",
            "        MCCD       0.56      0.58      0.57       129\n",
            "           N       0.39      0.99      0.56       128\n",
            "          PD       0.98      0.76      0.86       129\n",
            "          T1       0.38      0.30      0.33       128\n",
            "          T2       0.47      0.24      0.32       128\n",
            "          T3       0.53      0.16      0.24       128\n",
            "\n",
            "    accuracy                           0.51      1283\n",
            "   macro avg       0.56      0.51      0.49      1283\n",
            "weighted avg       0.56      0.51      0.49      1283\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "Train Accuracy: 0.454\n",
            "Test Accuracy:  0.456\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.74      0.27      0.39       128\n",
            "          D2       0.73      0.23      0.36       128\n",
            "        HCCD       0.70      0.80      0.74       128\n",
            "        LCCD       0.40      0.43      0.42       129\n",
            "        MCCD       0.39      0.35      0.37       129\n",
            "           N       0.35      0.98      0.51       128\n",
            "          PD       0.99      0.66      0.79       129\n",
            "          T1       0.28      0.66      0.40       128\n",
            "          T2       0.56      0.12      0.19       128\n",
            "          T3       0.32      0.07      0.12       128\n",
            "\n",
            "    accuracy                           0.46      1283\n",
            "   macro avg       0.55      0.46      0.43      1283\n",
            "weighted avg       0.55      0.46      0.43      1283\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-637919023.py:90: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"viridis\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# 1. Load the dataset\n",
        "df = pd.read_csv(\"fault type.csv\")\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 2. Split features and target\n",
        "X = df.drop(\"fault type\", axis=1)\n",
        "y = df[\"fault type\"]\n",
        "\n",
        "# 3. Feature selection\n",
        "selector = SelectKBest(score_func=f_classif, k=min(15, X.shape[1]))\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# 4. Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "\n",
        "# 5. Handle class imbalance using SMOTE\n",
        "class_counts = Counter(y)\n",
        "min_class_count = min(class_counts.values())\n",
        "k_neighbors = min(5, min_class_count - 1)\n",
        "if k_neighbors < 1:\n",
        "    k_neighbors = 1\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# 6. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.75, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# 7. Define machine learning models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=5, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000, C=1.0, penalty='l2', random_state=42),\n",
        "    \"SVM\": SVC(C=1.0, kernel='rbf', gamma='scale')\n",
        "}\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "# ðŸ”§ Ensure 'outputs' folder exists\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# 8. Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    accuracies[name] = test_acc\n",
        "\n",
        "    print(f\"Train Accuracy: {train_acc:.3f}\")\n",
        "    print(f\"Test Accuracy:  {test_acc:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"outputs/{name}_confusion_matrix_improved.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# 9. Plot accuracy comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"viridis\")\n",
        "plt.title(\"Improved Model Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/improved_accuracy_comparison.png\", dpi=300)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import os\n",
        "\n",
        "# ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "df_full = pd.read_csv(\"fault type.csv\")\n",
        "df_full.fillna(df_full.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 2. ÙØµÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ (X) ÙˆØ§Ù„Ù‡Ø¯Ù (y)\n",
        "X_train = df_full.drop(\"fault type\", axis=1)\n",
        "y_train = df_full[\"fault type\"]\n",
        "\n",
        "# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¹Ù…ÙˆØ¯ \"fault type\" Ù„Ù„ØªÙ†Ø¨Ø¤\n",
        "df_unlabeled = pd.read_csv(\"fault type.csv\").drop(\"fault type\", axis=1)\n",
        "df_unlabeled.fillna(df_unlabeled.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 4. Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø§Ù„Ø®ØµØ§Ø¦Øµ\n",
        "selector = SelectKBest(score_func=f_classif, k=min(15, X_train.shape[1]))\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_unlabeled_selected = selector.transform(df_unlabeled)\n",
        "\n",
        "# 5. ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_unlabeled_scaled = scaler.transform(X_unlabeled_selected)\n",
        "\n",
        "# 6. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 7. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØµÙ†ÙØ©\n",
        "predictions = model.predict(X_unlabeled_scaled)\n",
        "\n",
        "# 8. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯\n",
        "df_predictions = df_unlabeled.copy()\n",
        "df_predictions[\"Predicted Fault Type\"] = predictions\n",
        "df_predictions.to_csv(\"predicted_faults.csv\", index=False)\n",
        "print(\"âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ØŒ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù predicted_faults.csv\")\n",
        "\n",
        "# 9. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© ÙˆÙ†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©\n",
        "accuracy = accuracy_score(y_train, predictions)\n",
        "print(f\"ðŸ” Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©: {accuracy * 100:.2f}%\")\n",
        "print(\"ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\\n\", classification_report(y_train, predictions))\n",
        "\n",
        "# 10. Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ\n",
        "cm = confusion_matrix(y_train, predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/confusion_matrix.png\", dpi=300)\n",
        "plt.close()\n",
        "print(\"ðŸ“ˆ ØªÙ… Ø­ÙØ¸ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ ÙÙŠ outputs/confusion_matrix.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydtS7VVPpJFl",
        "outputId": "27d36b05-b952-4d7e-d6f1-0332a7e880b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ØŒ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù predicted_faults.csv\n",
            "ðŸ” Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©: 98.71%\n",
            "ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       1.00      1.00      1.00        63\n",
            "          D2       0.99      1.00      0.99        80\n",
            "        HCCD       1.00      0.82      0.90        11\n",
            "        LCCD       0.98      1.00      0.99       171\n",
            "        MCCD       0.98      1.00      0.99        61\n",
            "           N       1.00      1.00      1.00        97\n",
            "          PD       1.00      0.96      0.98        23\n",
            "          T1       1.00      0.92      0.96        13\n",
            "          T2       0.98      0.89      0.93        45\n",
            "          T3       0.98      1.00      0.99       131\n",
            "\n",
            "    accuracy                           0.99       695\n",
            "   macro avg       0.99      0.96      0.97       695\n",
            "weighted avg       0.99      0.99      0.99       695\n",
            "\n",
            "ðŸ“ˆ ØªÙ… Ø­ÙØ¸ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ ÙÙŠ outputs/confusion_matrix.png\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJON5I33ZTwt",
        "outputId": "c7ff9152-c05f-4ba8-d862-41dd4f776d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest ---\n",
            "Train Accuracy: 0.999\n",
            "Test Accuracy:  0.892\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.85      0.82      0.84        85\n",
            "          D2       0.82      0.80      0.81        85\n",
            "        HCCD       0.98      0.94      0.96        86\n",
            "        LCCD       0.89      0.86      0.88        86\n",
            "        MCCD       0.88      0.97      0.92        86\n",
            "           N       0.93      1.00      0.97        85\n",
            "          PD       1.00      0.95      0.98        86\n",
            "          T1       0.95      0.92      0.93        85\n",
            "          T2       0.77      0.88      0.82        85\n",
            "          T3       0.86      0.78      0.82        86\n",
            "\n",
            "    accuracy                           0.89       855\n",
            "   macro avg       0.89      0.89      0.89       855\n",
            "weighted avg       0.89      0.89      0.89       855\n",
            "\n",
            "\n",
            "--- Extra Trees ---\n",
            "Train Accuracy: 0.935\n",
            "Test Accuracy:  0.842\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.92      0.67      0.78        85\n",
            "          D2       0.83      0.82      0.83        85\n",
            "        HCCD       0.97      0.99      0.98        86\n",
            "        LCCD       0.67      0.77      0.72        86\n",
            "        MCCD       0.84      0.93      0.88        86\n",
            "           N       0.72      1.00      0.84        85\n",
            "          PD       1.00      0.91      0.95        86\n",
            "          T1       0.85      0.96      0.90        85\n",
            "          T2       0.85      0.71      0.77        85\n",
            "          T3       0.89      0.66      0.76        86\n",
            "\n",
            "    accuracy                           0.84       855\n",
            "   macro avg       0.85      0.84      0.84       855\n",
            "weighted avg       0.85      0.84      0.84       855\n",
            "\n",
            "\n",
            "--- Decision Tree ---\n",
            "Train Accuracy: 0.913\n",
            "Test Accuracy:  0.794\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.76      0.75      0.76        85\n",
            "          D2       0.65      0.55      0.60        85\n",
            "        HCCD       0.93      0.92      0.92        86\n",
            "        LCCD       0.74      0.78      0.76        86\n",
            "        MCCD       0.89      0.87      0.88        86\n",
            "           N       0.97      0.99      0.98        85\n",
            "          PD       0.99      0.91      0.95        86\n",
            "          T1       0.88      0.81      0.85        85\n",
            "          T2       0.53      0.69      0.60        85\n",
            "          T3       0.68      0.66      0.67        86\n",
            "\n",
            "    accuracy                           0.79       855\n",
            "   macro avg       0.80      0.79      0.80       855\n",
            "weighted avg       0.80      0.79      0.80       855\n",
            "\n",
            "\n",
            "--- Logistic Regression ---\n",
            "Train Accuracy: 0.506\n",
            "Test Accuracy:  0.522\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.68      0.33      0.44        85\n",
            "          D2       0.70      0.38      0.49        85\n",
            "        HCCD       0.76      0.91      0.83        86\n",
            "        LCCD       0.30      0.57      0.40        86\n",
            "        MCCD       0.53      0.67      0.59        86\n",
            "           N       0.43      0.99      0.60        85\n",
            "          PD       0.98      0.74      0.85        86\n",
            "          T1       0.33      0.24      0.27        85\n",
            "          T2       0.43      0.19      0.26        85\n",
            "          T3       0.50      0.20      0.28        86\n",
            "\n",
            "    accuracy                           0.52       855\n",
            "   macro avg       0.56      0.52      0.50       855\n",
            "weighted avg       0.56      0.52      0.50       855\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "Train Accuracy: 0.498\n",
            "Test Accuracy:  0.490\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       0.84      0.25      0.38        85\n",
            "          D2       0.87      0.31      0.45        85\n",
            "        HCCD       0.80      0.85      0.82        86\n",
            "        LCCD       0.62      0.33      0.43        86\n",
            "        MCCD       0.44      0.65      0.52        86\n",
            "           N       0.34      1.00      0.51        85\n",
            "          PD       0.98      0.67      0.80        86\n",
            "          T1       0.28      0.64      0.39        85\n",
            "          T2       0.56      0.11      0.18        85\n",
            "          T3       0.50      0.10      0.17        86\n",
            "\n",
            "    accuracy                           0.49       855\n",
            "   macro avg       0.62      0.49      0.47       855\n",
            "weighted avg       0.62      0.49      0.47       855\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-3066201412.py:90: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"viridis\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# 1. Load the dataset\n",
        "df = pd.read_csv(\"fault type.csv\")\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 2. Split features and target\n",
        "X = df.drop(\"fault type\", axis=1)\n",
        "y = df[\"fault type\"]\n",
        "\n",
        "# 3. Feature selection\n",
        "selector = SelectKBest(score_func=f_classif, k=min(15, X.shape[1]))\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# 4. Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "\n",
        "# 5. Handle class imbalance using SMOTE\n",
        "class_counts = Counter(y)\n",
        "min_class_count = min(class_counts.values())\n",
        "k_neighbors = min(5, min_class_count - 1)\n",
        "if k_neighbors < 1:\n",
        "    k_neighbors = 1\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# 6. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.50, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# 7. Define machine learning models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=5, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000, C=1.0, penalty='l2', random_state=42),\n",
        "    \"SVM\": SVC(C=1.0, kernel='rbf', gamma='scale')\n",
        "}\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "# ðŸ”§ Ensure 'outputs' folder exists\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# 8. Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    accuracies[name] = test_acc\n",
        "\n",
        "    print(f\"Train Accuracy: {train_acc:.3f}\")\n",
        "    print(f\"Test Accuracy:  {test_acc:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"outputs/{name}_confusion_matrix_improved.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# 9. Plot accuracy comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"viridis\")\n",
        "plt.title(\"Improved Model Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/improved_accuracy_comparison.png\", dpi=300)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import os\n",
        "\n",
        "# ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "df_full = pd.read_csv(\"fault type.csv\")\n",
        "df_full.fillna(df_full.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 2. ÙØµÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ (X) ÙˆØ§Ù„Ù‡Ø¯Ù (y)\n",
        "X_train = df_full.drop(\"fault type\", axis=1)\n",
        "y_train = df_full[\"fault type\"]\n",
        "\n",
        "# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¹Ù…ÙˆØ¯ \"fault type\" Ù„Ù„ØªÙ†Ø¨Ø¤\n",
        "df_unlabeled = pd.read_csv(\"fault type.csv\").drop(\"fault type\", axis=1)\n",
        "df_unlabeled.fillna(df_unlabeled.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 4. Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø§Ù„Ø®ØµØ§Ø¦Øµ\n",
        "selector = SelectKBest(score_func=f_classif, k=min(15, X_train.shape[1]))\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_unlabeled_selected = selector.transform(df_unlabeled)\n",
        "\n",
        "# 5. ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_unlabeled_scaled = scaler.transform(X_unlabeled_selected)\n",
        "\n",
        "# 6. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 7. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØµÙ†ÙØ©\n",
        "predictions = model.predict(X_unlabeled_scaled)\n",
        "\n",
        "# 8. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯\n",
        "df_predictions = df_unlabeled.copy()\n",
        "df_predictions[\"Predicted Fault Type\"] = predictions\n",
        "df_predictions.to_csv(\"predicted_faults.csv\", index=False)\n",
        "print(\"âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ØŒ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù predicted_faults.csv\")\n",
        "\n",
        "# 9. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© ÙˆÙ†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©\n",
        "accuracy = accuracy_score(y_train, predictions)\n",
        "print(f\"ðŸ” Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©: {accuracy * 100:.2f}%\")\n",
        "print(\"ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\\n\", classification_report(y_train, predictions))\n",
        "\n",
        "# 10. Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ\n",
        "cm = confusion_matrix(y_train, predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/confusion_matrix.png\", dpi=300)\n",
        "plt.close()\n",
        "print(\"ðŸ“ˆ ØªÙ… Ø­ÙØ¸ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ ÙÙŠ outputs/confusion_matrix.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNrU-gGCbTuY",
        "outputId": "2112fe8a-555f-418c-b105-3235cc20f9cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ØŒ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù predicted_faults.csv\n",
            "ðŸ” Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©: 98.71%\n",
            "ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          D1       1.00      1.00      1.00        63\n",
            "          D2       0.99      1.00      0.99        80\n",
            "        HCCD       1.00      0.82      0.90        11\n",
            "        LCCD       0.98      1.00      0.99       171\n",
            "        MCCD       0.98      1.00      0.99        61\n",
            "           N       1.00      1.00      1.00        97\n",
            "          PD       1.00      0.96      0.98        23\n",
            "          T1       1.00      0.92      0.96        13\n",
            "          T2       0.98      0.89      0.93        45\n",
            "          T3       0.98      1.00      0.99       131\n",
            "\n",
            "    accuracy                           0.99       695\n",
            "   macro avg       0.99      0.96      0.97       695\n",
            "weighted avg       0.99      0.99      0.99       695\n",
            "\n",
            "ðŸ“ˆ ØªÙ… Ø­ÙØ¸ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ ÙÙŠ outputs/confusion_matrix.png\n"
          ]
        }
      ]
    }
  ]
}